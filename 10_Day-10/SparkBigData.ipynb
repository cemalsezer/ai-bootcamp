{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKXAjxHr7t-k",
        "outputId": "408e4285-080e-4130-99ba-523c439a145e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=dc04113bb39a2a29e35ffbf5d1c972185b1cc2e54c65db897ab1d0c489ebed54\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/59/a0/a1a0624b5e865fd389919c1a10f53aec9b12195d6747710baf\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ikS0XSy7CPU",
        "outputId": "5339745a-5d48-4ba7-923f-7710f7face6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16, 4, 25, 4]\n"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "import collections\n",
        "sc=SparkContext()\n",
        "rdd=sc.parallelize([4,2,5,2,])\n",
        "sq=rdd.map(lambda x:x*x)\n",
        "print(sq.collect()\n",
        ")\n",
        "sc.stop()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop()"
      ],
      "metadata": {
        "id": "nMZkCcF_-3q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "import collections\n",
        "conf=SparkConf().setMaster(\"local\").setAppName(\"RatingHistogram\")\n",
        "sc=SparkContext(conf=conf)\n",
        "lines=sc.textFile('u.data')\n",
        "ratings=lines.map(lambda x:x.split()[2])\n",
        "result=ratings.countByValue()\n",
        "sortedResults=collections.OrderedDict(sorted(result.items()))\n",
        "for key, values in sortedResults.items():\n",
        "  print(key, values)\n",
        "sc.stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLQL-zyY7-Ji",
        "outputId": "f33f7127-2117-4973-dbfc-a40a121cca64"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 6111\n",
            "2 11370\n",
            "3 27145\n",
            "4 34174\n",
            "5 21203\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method SparkContext.stop of <SparkContext master=local appName=RatingHistogram>>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop()"
      ],
      "metadata": {
        "id": "2t9HSjSE-0IK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "\n",
        "conf = SparkConf().setMaster(\"local\").setAppName(\"FriendsByAge\")\n",
        "sc = SparkContext(conf = conf)\n",
        "\n",
        "def parseLine(line):\n",
        "  fields = line.split(',')\n",
        "  age = int(fields[2])\n",
        "  numFriends = int(fields[3])\n",
        "  return (age, numFriends)\n",
        "  \n",
        "lines = sc.textFile(\"fakefriends.csv\")\n",
        "rdd = lines.map(parseLine)\n",
        "totalsByAge = rdd.mapValues(lambda x: (x, 1)).reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
        "averagesByAge = totalsByAge.mapValues(lambda x: int(x[0] / x[1]))\n",
        "results = averagesByAge.collect()\n",
        "for result in results:\n",
        "  print(result)\n",
        "\n",
        "sc.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhnfhDtn-Vaq",
        "outputId": "c08b6952-088d-470b-85f3-740152a5880e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(33, 325)\n",
            "(26, 242)\n",
            "(55, 295)\n",
            "(40, 250)\n",
            "(68, 269)\n",
            "(59, 220)\n",
            "(37, 249)\n",
            "(54, 278)\n",
            "(38, 193)\n",
            "(27, 228)\n",
            "(53, 222)\n",
            "(57, 258)\n",
            "(56, 306)\n",
            "(43, 230)\n",
            "(36, 246)\n",
            "(22, 206)\n",
            "(35, 211)\n",
            "(45, 309)\n",
            "(60, 202)\n",
            "(67, 214)\n",
            "(19, 213)\n",
            "(30, 235)\n",
            "(51, 302)\n",
            "(25, 197)\n",
            "(21, 350)\n",
            "(42, 303)\n",
            "(49, 184)\n",
            "(48, 281)\n",
            "(50, 254)\n",
            "(39, 169)\n",
            "(32, 207)\n",
            "(58, 116)\n",
            "(64, 281)\n",
            "(31, 267)\n",
            "(52, 340)\n",
            "(24, 233)\n",
            "(20, 165)\n",
            "(62, 220)\n",
            "(41, 268)\n",
            "(44, 282)\n",
            "(69, 235)\n",
            "(65, 298)\n",
            "(61, 256)\n",
            "(28, 209)\n",
            "(66, 276)\n",
            "(46, 223)\n",
            "(29, 215)\n",
            "(18, 343)\n",
            "(47, 233)\n",
            "(34, 245)\n",
            "(63, 384)\n",
            "(23, 246)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop()\n"
      ],
      "metadata": {
        "id": "ZO4hfo2J_kXS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}